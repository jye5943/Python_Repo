{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "import csv\n",
    "import random\n",
    "from http.server import BaseHTTPRequestHandler, HTTPServer  # 이거 파이썬 3.0버전에서만 사용가능함\n",
    "from socketserver import ThreadingMixIn\n",
    "import json\n",
    "import re\n",
    "from urllib.parse import parse_qs\n",
    "from urllib.parse import urlparse\n",
    "import threading\n",
    "import cgi\n",
    "import uuid\n",
    "from tempfile import NamedTemporaryFile\n",
    "import shutil\n",
    "import requests  # for sending new block to other nodes\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "PORT_NUMBER = 8099\n",
    "g_txFileName = \"txData.csv\"\n",
    "g_bcFileName = \"blockchain.csv\"\n",
    "g_nodelstFileName = \"nodelst.csv\"\n",
    "g_receiveNewBlock = \"/node/receiveNewBlock\"\n",
    "g_difficulty = 2\n",
    "g_maximumTry = 100\n",
    "# -----------------------------------------V01 : 완\n",
    "# 최대 보유 거래내역 증가\n",
    "g_maximumGetTx = 50\n",
    "g_nodeList = {'127.0.0.1': '8096'}  # trusted server list, should be checked manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host='192.168.110.12',port=3300,user='root',passwd='root',db='bcsvr2')\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        sql = '''\n",
    "            CREATE TABLE test4(\n",
    "                idx int(100) NOT NULL AUTO_INCREMENT PRIMARY KEY,\n",
    "                previousHash varchar(255) NOT NULL,\n",
    "                timestamp varchar(255) NOT NULL,\n",
    "                data varchar(255) NOT NULL,\n",
    "                currentHash varchar(255) NOT NULL,\n",
    "                proof varchar(255) NOT NULL,\n",
    "                merkleHash varchar(255) NOT NULL\n",
    "            ) ENGINE=InnoDB DEFAULT CHARSET=utf8\n",
    "'''\n",
    "        cursor.execute(sql)\n",
    "    conn.commit()\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "data = cursor.fetchall()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block:\n",
    "\n",
    "    def __init__(self, index, previousHash, timestamp, data, currentHash, proof, merkleHash):\n",
    "        self.index = index\n",
    "        self.previousHash = previousHash\n",
    "        self.timestamp = timestamp\n",
    "        self.data = data\n",
    "        self.currentHash = currentHash\n",
    "        self.proof = proof\n",
    "        # -----------------------------------------V01 : 완\n",
    "        # 머클트리로 추출한 해쉬\n",
    "        self.merkleHash = merkleHash\n",
    "        \n",
    "    def toJSON(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class txData:\n",
    "\n",
    "    def __init__(self, commitYN, sender, amount, receiver, fee, uuid, transactionTime):\n",
    "        self.commitYN = commitYN\n",
    "        self.sender = sender\n",
    "        self.amount = amount\n",
    "        self.receiver = receiver\n",
    "        self.fee = fee\n",
    "        self.uuid = uuid\n",
    "        self.transactionTime = transactionTime\n",
    "\n",
    "    # block과 hash를 생성해서 block 객체에 담아서 리턴한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateGenesisBlock():\n",
    "    print(\"generateGenesisBlock is called\")\n",
    "\n",
    "    # teimestamp는 1970년 1월1일 자정 이후로 초단위로 측정한 절대시간을 의미하는 단순변수이며,\n",
    "    # 이 변수에 time.time()으로 위에서부터 누적된 초를 float자료형으로 반환하여 대입한다.\n",
    "    timestamp = time.time()\n",
    "    # 불러온 시간 확인\n",
    "    print(\"time.time() => %f \\n\" % timestamp)\n",
    "    # hash생성\n",
    "    txDataList = readTx(g_txFileName)\n",
    "    merkleHash = calculateMerkleHash(txDataList)\n",
    "\n",
    "    # -----------------------------------------V01 : 완\n",
    "    #블록 hash생성에 merkleHash 추가\n",
    "    tempHash = calculateHash(0, '0', timestamp, 0, merkleHash)\n",
    "    print(tempHash)\n",
    "    # -----------------------------------------V01 : 완\n",
    "    # 이부분에 merkleHash를 추가시켜 반환한다. 총 7개\n",
    "    # genesis block의 생성부터 거래원장의 고유넘버가 존재하기때문에 그걸 가져와서 blockdata에 넣어준다.\n",
    "    txDataList = readTx(g_txFileName)\n",
    "    genesisblockData = getTxData(txDataList)\n",
    "    return Block(0, '0', timestamp, genesisblockData, tempHash, 0, merkleHash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateHash(index, previousHash, timestamp, proof, merkleHash):\n",
    "    value = str(index) + str(previousHash) + str(timestamp) + str(proof) + merkleHash\n",
    "    # 인자로 받은 모든 데이터를 차례대로 더한 value 문자열을 utf-8로 인코딩한후 hashlib.sha256를 통해 해쉬암호화한다\n",
    "    # sha256은 암호학적 해쉬함수의 한 종류. utf-8로 인코딩을 하지않고 쓰면 에러난다. 반환값은 hash객체.hash자료형 아니다. 객체다\n",
    "    sha = hashlib.sha256(value.encode('utf-8'))\n",
    "    # hash객체에서 제공하는 hexdigest() 메소드는 오직 16진수숫자만 포함하는 이중길이(?)의 해쉬값을 문자열로 변환하여 반환한다.\n",
    "    return str(sha.hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------V01 : 완\n",
    "# 머클해쉬추출 작성\n",
    "#-----------------------------------------V02 : 완\n",
    "# txData객체 리스트를 받아 문자열 리스트로 변환 후 rcGetMerkleHash에 인자로 던지게끔 수정.\n",
    "def calculateMerkleHash(importedTx) :\n",
    "    #txData객체 리스트를 문자열 리스트로 변환\n",
    "    txDataList = []\n",
    "    print(\"hash merkling..................\")\n",
    "    if len(importedTx) > 0:\n",
    "        for i in importedTx:\n",
    "            print(i.__dict__)\n",
    "            transaction = \"[\" + i.uuid + \"]\" \"UserID \" + i.sender + \" sent \" + i.amount + \" bitTokens to UserID \" + i.receiver + \" fee \"+ i.fee + \". \"  #\n",
    "            print(transaction)\n",
    "            txDataList.append(transaction)\n",
    "    #문자열 리스트를 머클트리 재귀함수에 던져준다.\n",
    "    return rcGetMerkleHash(txDataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------V01 : 완\n",
    " # 머클트리해쉬 재귀함수. target = txData의 문자열 리스트\n",
    "def rcGetMerkleHash(target) :\n",
    "    strBinaryTxData = \"\"\n",
    "    #check\n",
    "    print(\"current len of Target =  \" + str(len(target)))\n",
    "    endIndexOfTarget = len(target) - 1\n",
    "    #taget의 원소가 1개라면 종료.\n",
    "    if len(target) <= 1 :\n",
    "        sha = hashlib.sha256(target[0].encode('utf-8'))\n",
    "        return str(sha.hexdigest())\n",
    "    #1개 이상이라면 1개가 될때까지 계속 해쉬화\n",
    "    else :\n",
    "        newTarget = []\n",
    "        for i in range(endIndexOfTarget - 1):\n",
    "            if i % 2 == 0 :\n",
    "                strBinaryTxData = strBinaryTxData + target[i] + target[i+1]\n",
    "                sha = hashlib.sha256(target[i].encode('utf-8'))\n",
    "                newTarget.append(str(sha.hexdigest()))\n",
    "\n",
    "        #target리스트의 길이가 홀수라면\n",
    "        if (len(target) % 2) != 0:\n",
    "            sha = hashlib.sha256(target[endIndexOfTarget].encode('utf-8'))\n",
    "            newTarget.append(str(sha.hexdigest()))\n",
    "        #짝수라면\n",
    "        else :\n",
    "            strBinaryTxData = strBinaryTxData + target[endIndexOfTarget-1] + target[endIndexOfTarget]\n",
    "            sha = hashlib.sha256(strBinaryTxData.encode('utf-8'))\n",
    "            newTarget.append(str(sha.hexdigest()))\n",
    "        #재귀   \n",
    "        return rcGetMerkleHash(newTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateHashForBlock(block):\n",
    "    # -----------------------------------------V01 : 완\n",
    "    # data대신 머클트리로 생성한 해쉬를 추가\n",
    "    return calculateHash(block.index, block.previousHash, block.timestamp, block.proof, block.merkleHash)\n",
    "\n",
    "\n",
    "def getLatestBlock(blockchain):\n",
    "    return blockchain[len(blockchain) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------V01 : 완\n",
    "# -----------------------------------------V02 : 완\n",
    "# blockData를 이 fucntion에서 가져와 merkleHash를 추출하여 블록을 생성하게 바꾼다.\n",
    "def generateNextBlock(blockchain, timestamp, proof):\n",
    "    previousBlock = getLatestBlock(blockchain)\n",
    "    nextIndex = int(previousBlock.index) + 1\n",
    "    nextTimestamp = timestamp\n",
    "    #blockdata 가져오기\n",
    "    txDataList = readTx(g_txFileName)\n",
    "    strTxData = getTxData(txDataList)\n",
    "    #머클해쉬 생성\n",
    "    merkleHash = calculateMerkleHash(txDataList)\n",
    "    # -----------------------------------------V01 : 완\n",
    "    # 이부분의 blockData를 merkleHash로 바꿔준다\n",
    "    nextHash = calculateHash(nextIndex, previousBlock.currentHash, nextTimestamp, proof, merkleHash)\n",
    "    # index, previousHash, timestamp, data, currentHash, proof, merkleHash\n",
    "    # -----------------------------------------V01 : 완\n",
    "    # block 객체에 merklehash를 추가한다.\n",
    "    return Block(nextIndex, previousBlock.currentHash, nextTimestamp, strTxData, nextHash, proof, merkleHash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host='192.168.110.12',port=3300,user='root',passwd='root',db='bcsvr2')\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        sql = '''\n",
    "            INSERT INTO test4\n",
    "                VALUES(0,'이전해시','타임스탬프','데이터','현재해시','증명','머클해시');\n",
    "'''\n",
    "        cursor.execute(sql)\n",
    "    conn.commit()\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter또한 block객체list이다.\n",
    "def writeBlockchain(blockchain):\n",
    "    # list\n",
    "    blockchainList =[]\n",
    "    for block in blockchain:\n",
    "        blockList = [block.index, block.previousHash, str(block.timestamp), block.data, block.currentHash, block.proof, block.merkleHash]\n",
    "        blockchainList.append(blockList)\n",
    "    if len(blockchainList) > 0 :\n",
    "        try:\n",
    "            conn = pymysql.connect(host='192.168.110.12',port=3300,user='root',passwd='root',db='bcsvr2')\n",
    "            with conn.cursor() as cursor:\n",
    "                sql = '''\n",
    "                    INSERT INTO test3\n",
    "                        VALUES(block.index,block.previousHash,str(block.timestamp), block.data,block.currentHash,block.proof,block.merkleHash);\n",
    "        '''\n",
    "                cursor.execute(sql)\n",
    "            conn.commit()\n",
    "        finally:\n",
    "            conn.close()\n",
    "            print(\"Complete updating blockchain.csv\")\n",
    "\n",
    "    else:\n",
    "        print(\"List is empty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode의 초기값은 internal이므로, mode가 명시되어있지 않는 경우, blockchain.csv파일이 존재하지 않을 때, except로 빠져\n",
    "# internal에 해당하는 if문이 실행된다.\n",
    "def readBlockchain(blockchainFilePath, mode='internal'):\n",
    "    print(\"readBlockchain\")\n",
    "    importedBlockchain = []\n",
    "\n",
    "    try:\n",
    "        # blockchainFilePath = 'blcokchain.csv' 즉, 해당 파일을 'r' 읽기 형태로 file이라는 별칭(객체)으로 연다.\n",
    "        with open(blockchainFilePath, 'r', newline='') as file:\n",
    "            # csv.reader(별칭)이 성공하면 reader객체를 리턴한다.\n",
    "            blockReader = csv.reader(file)\n",
    "            # file의 한 라인씩을 가져온다.\n",
    "            for line in blockReader:\n",
    "                # -----------------------------------------V01 : 04 완\n",
    "                # line[6] 추가.\n",
    "                block = Block(line[0], line[1], line[2], line[3], line[4], line[5], line[6])\n",
    "                importedBlockchain.append(block)\n",
    "\n",
    "        print(\"Pulling blockchain from csv...\")\n",
    "\n",
    "        return importedBlockchain\n",
    "\n",
    "    # 가장 맨처음에 데이터확인url을 날리는 경우,  'blockchain.csv' 파일이 존재하지 않으므로 csv.reader에서 예외처리로 넘어오게된다.\n",
    "    except:\n",
    "        # 현재 모드가 internal(내부)이라면, 새로운 블록을 생성한다.\n",
    "        if mode == 'internal':\n",
    "            # -----------------------------------------V01 : 완\n",
    "            # genesis block 생성부터 txData.csv를 유지한다.\n",
    "            tempList = []\n",
    "            tempDict = {\"sender\": \"Genesis Block\", \"amount\": \"1000\", \"receiver\": \"Hwang\", \"fee\": \"50\"}\n",
    "            tempList.append(tempDict)\n",
    "            res = newtx(tempList)\n",
    "            # -----------------------------------------V01 : 01 완\n",
    "            # txData가 제대로 만들어 졌다면\n",
    "            if res == 1:\n",
    "                blockchain = generateGenesisBlock()\n",
    "                # 생성된 블록을 importedBlockchain의 block객체list에 넣는다.\n",
    "                importedBlockchain.append(blockchain)\n",
    "                # block객체list를 인자로 던진다.\n",
    "                writeBlockchain(importedBlockchain)\n",
    "\n",
    "            return importedBlockchain\n",
    "\n",
    "\n",
    "\n",
    "        # 현재 모드가 external(외부)이라면,\n",
    "        else:\n",
    "            # None 리턴\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block객체의\n",
    "def updateTx(blockData):\n",
    "    # 정규표현식 설정\n",
    "    phrase = re.compile(\n",
    "        r\"\\w+[-]\\w+[-]\\w+[-]\\w+[-]\\w+\")  # [6b3b3c1e-858d-4e3b-b012-8faac98b49a8]UserID hwang sent 333 bitTokens to UserID kim.\n",
    "    # block객체의 data field에서 해당 정규표현식과 매칭되는 부분을 전부 찾는다. data는 string 변수.\n",
    "    # 주의할 점은, block 최초로 생성되었 때의 block인 genesis Block의 data는 \"genesis Block\"이므로, matchList는 결과적으로 아무것도 들어있지 않는\n",
    "    # 상태이다. 다만, block이 최초로 생성되는 상황에서는 거래가 있을수가 없기 때문인지, 아니면 genesis Block은 그자체로 거래불가인지는 모르겠음.\n",
    "    matchList = phrase.findall(blockData.data)\n",
    "\n",
    "    # 해당 block객체가 거래내역(data)이 없는 경우\n",
    "    if len(matchList) == 0:\n",
    "        print(\"No Match Found! \" + str(blockData.data) + \"block idx: \" + str(blockData.index))\n",
    "        # block의 data field 에서 거래내역을 찾지 못했으므로 바로 리턴\n",
    "        return\n",
    "    # 거래내역이 있으면 이쪽으로 코드가 계속 진행된다.\n",
    "    # data 내에 정규표현식에 해당하는 문자열, 즉 거래내역이 존재하는 경우, 임시로 파일 스트림을 연다.\n",
    "    # 임시로 여는 파일은 scope안에서면 사용되고 사라진다.\n",
    "    # 왜 임시로 열었는지는 의문. 왜 임시로 열고 저장은 하는지는 의문. 왜 임시로 열었는데 delete = false인지는 의문     ???????????????????????\n",
    "    # 참고사이트 : https://medium.com/@silmari/python-tempfile-%EC%9E%84%EC%8B%9C%ED%8C%8C%EC%9D%BC-%EB%B0%8F-%ED%8F%B4%EB%8D%94-%EB%A7%8C%EB%93%A4%EA%B8%B0-86ea533086ce\n",
    "    tempfile = NamedTemporaryFile(mode='w', newline='', delete=False)\n",
    "\n",
    "    # \"txdata.csv\"파일을 읽기용과 쓰기용으로 각각 파일스트림을 연다. as 뒤에, 위에서 쓴 tempfile이 여기서도 쓰여질수 있는지는 의문           ???????????????????\n",
    "    with open(g_txFileName, 'r') as csvfile, tempfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        writer = csv.writer(tempfile)\n",
    "        # 각 행들을 순차적으로 읽어들여와\n",
    "        for row in reader:\n",
    "            # -----------------------------------------V01 : 01 완\n",
    "            # row[4] -> row[5]\n",
    "            if row[5] in matchList:\n",
    "                print('updating row : ', row[5])\n",
    "                # 이 값이 정확히 무엇을 의미하는지는 모르겠으나, 다른 컬럼의 값은 그대로 유지하면서, row[0]만 1로 바꿔주고( 이부분을 업데이트하는 거임)\n",
    "                row[0] = 1\n",
    "            # \"txdata.csv'에 matchList의 해쉬코드가 있으면, 위의 작업을 하고, 없으면 아무것도 하지않는 채로 이전 데이터 그대로 쓰기용 파일에 저장한다.\n",
    "            writer.writerow(row)\n",
    "\n",
    "    # 파일을 이동시키는 shutil.move를 이용해 덮어씌운다. tempfile.name의 내용이 g_txFileName으로 덮어씌워지고, tempfile.name은 존재하지 않는다.\n",
    "    shutil.move(tempfile.name, g_txFileName)\n",
    "    # 파일스트림을 닫는다. 위에서 with ~ as 구문으로 자동으로 close()되게 되있는데 여기서 또 닫는지는 의문.          ????????????????????\n",
    "    csvfile.close()\n",
    "    tempfile.close()\n",
    "    print('txData updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTx(txRawData):\n",
    "    print(g_txFileName)\n",
    "    txDataList = []\n",
    "    for txDatum in txRawData:\n",
    "        txList = [txDatum.commitYN, txDatum.sender, txDatum.amount, txDatum.receiver, txDatum.fee, txDatum.uuid, txDatum.transactionTime]\n",
    "        txDataList.append(txList)\n",
    "\n",
    "    tempfile = NamedTemporaryFile(mode='w', newline='', delete=False)\n",
    "    try:\n",
    "        with open(g_txFileName, 'r', newline='') as csvfile, tempfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            writer = csv.writer(tempfile)\n",
    "            for row in reader:\n",
    "                if row:\n",
    "                    writer.writerow(row)\n",
    "            # adding new tx\n",
    "            writer.writerows(txDataList)\n",
    "        shutil.move(tempfile.name, g_txFileName)\n",
    "        csvfile.close()\n",
    "        tempfile.close()\n",
    "    except:\n",
    "        # this is 1st time of creating txFile\n",
    "        try:\n",
    "            with open(g_txFileName, \"w\", newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerows(txDataList)\n",
    "        except:\n",
    "            return 0\n",
    "    return 1\n",
    "    print('txData written to txData.csv.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------V02 : 완\n",
    "# 거래내역에서 column[0]의 값이 '0' 인 거래내역부터 순차적으로 가져온다.\n",
    "# 블록생성시의 txData와 txData내역 자체를 요청했을 떄의 txData 부분을 나눈다.\n",
    "def readTx(txFilePath, mode='internal'):\n",
    "    importedTx = []\n",
    "    zeroCount = 0;\n",
    "    getAllTxData = False\n",
    "\n",
    "    if mode == 'external' :\n",
    "        getAllTxData = True\n",
    "\n",
    "    print(\"readTx. mode : \" + mode)\n",
    "    try:\n",
    "        with open(txFilePath, 'r', newline='') as file:\n",
    "\n",
    "            txReader = csv.reader(file)\n",
    "            print(\"file open completed.\")\n",
    "\n",
    "            for row in txReader :\n",
    "                # -----------------------------------------V02 : 완\n",
    "                # mode =\"internal\" 인 경우(commitYn이 0인 row가 필요한 경우)\n",
    "                if not getAllTxData :\n",
    "                    # -----------------------------------------V02 : 완\n",
    "                    # block에 담을 수 있는 최대 거래내역 개수를 초과하면 중단.\n",
    "                    if zeroCount < g_maximumGetTx :\n",
    "                        if row[0] == '0' :  # find unmined txData\n",
    "                            # -----------------------------------------V01 : 완\n",
    "                            # row[5] 추가\n",
    "                            # -----------------------------------------V02 : 완\n",
    "                            # row[6] 추가\n",
    "                            line = txData(row[0], row[1], row[2], row[3], row[4], row[5], row[6])\n",
    "                            zeroCount = zeroCount + 1\n",
    "                        #개조심... try안에 if에 else가 안달려있으니까 바로 exception으로 빠지더라.\n",
    "                        else : continue\n",
    "                # mode = \"external\" 인 경우(모든 txData가 필요한 경우)\n",
    "                else :\n",
    "                    line = txData(row[0], row[1], row[2], row[3], row[4], row[5], row[6])\n",
    "\n",
    "                importedTx.append(line)\n",
    "        # mode =\"internal\" 인 경우(commitYn이 0인 row가 필요한 경우) 정렬을 해준다.\n",
    "        if not getAllTxData :\n",
    "            # 수수료가 큰 거래내역으로 정렬\n",
    "            sortedTxDataList = sorted(importedTx, key=lambda txData: int(txData.fee), reverse=True)\n",
    "        else :\n",
    "            sortedTxDataList = importedTx\n",
    "\n",
    "        print(\"Pulling txData from csv...\")\n",
    "        print(\"length : \" + str(len(sortedTxDataList)))\n",
    "        return sortedTxDataList\n",
    "    except:\n",
    "        print(\"Reading txData error..........\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m31\u001b[0m\n\u001b[1;33m    generateGenesisBlock()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# \"txdata.csv\"파일을 읽어와 거래내역을 전체를 string으로 캐스팅하여 반환한다.\n",
    "def getTxData(importedTx):\n",
    "    strTxData = ''\n",
    "    # importedTx의 값이\n",
    "    if len(importedTx) > 0:\n",
    "        for i in importedTx:\n",
    "            print(i.__dict__)\n",
    "            transaction = \"[\" + i.uuid + \"]\" \"UserID \" + i.sender + \" sent \" + i.amount + \" bitTokens to UserID \" + \\\n",
    "                          i.receiver + \" fee \"+ i.fee + \" transaction time \" + i.transactionTime + \". \"\n",
    "            print(transaction)\n",
    "            strTxData += transaction\n",
    "\n",
    "    return strTxData\n",
    "\n",
    "#----------------아래는 내가 바꿀 부분 ---------------------#\n",
    "# \"txdata.csv\"파일을 읽어와 거래내역을 전체를 string으로 캐스팅하여 반환한다.\n",
    "##  데이터들이 들어오고, 1) 채굴이 됐는지 안됐는지 검사 2) transaction pool이 비었는지 안 비었는지 검사 3) 각 경우에 수와 예외처리 \n",
    "\n",
    "def getTxData(importedTx): \n",
    "    strTxData = ''\n",
    "    # importedTx의 값이\n",
    "    if len(importedTx) == 0:  # 2) -> 거래내역이 없을 떄\n",
    "        if for i in importedTx:\n",
    "            print(i.__dict__)\n",
    "            transaction = \"[\" + i.uuid + \"]\" \"UserID \" + i.sender + \" sent \" + i.amount + \" bitTokens to UserID \" + \\\n",
    "                          i.receiver + \" fee \"+ i.fee + \" transaction time \" + i.transactionTime + \". \"\n",
    "            print(transaction)\n",
    "            strTxData += transaction\n",
    "\n",
    "            return strTxData\n",
    "    else \n",
    "            print(\"There's no data in Transaction Pool.\")\n",
    "        generateGenesisBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mineNewBlock(difficulty=g_difficulty, blockchainPath=g_bcFileName):\n",
    "    importedTx = readTx(g_txFileName)\n",
    "    strTxData = getTxData(importedTx)\n",
    "    if strTxData == '':\n",
    "        #genesis Blcok 생성\n",
    "        blockchain = readBlockchain(blockchainPath)\n",
    "\n",
    "        if len(blockchain) > 0 and len(blockchain) < 2:\n",
    "            print(\"Genesis block is mined.\")\n",
    "        else :\n",
    "            print(\"Failed to create Genesis block.\")\n",
    "        return\n",
    "\n",
    "    blockchain = readBlockchain(blockchainPath)\n",
    "    timestamp = time.time()\n",
    "    proof = 0\n",
    "    newBlockFound = False\n",
    "\n",
    "    print('Mining a block...')\n",
    "\n",
    "    while not newBlockFound:\n",
    "        newBlockAttempt = generateNextBlock(blockchain, timestamp, proof)\n",
    "        if newBlockAttempt.currentHash[0:difficulty] == '0' * difficulty:\n",
    "            stopTime = time.time()\n",
    "            timer = stopTime - timestamp\n",
    "            print('New block found with proof', proof, 'in', round(timer, 2), 'seconds.')\n",
    "\n",
    "            newBlockFound = True\n",
    "        else:\n",
    "            proof += 1\n",
    "\n",
    "    blockchain.append(newBlockAttempt)\n",
    "    writeBlockchain(blockchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mineNewBlock() : 294\n",
    "def mine():\n",
    "    mineNewBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------V01 : 완\n",
    "# 비교 대상에 merkleHash 추가\n",
    "def isSameBlock(block1, block2):\n",
    "    if str(block1.index) != str(block2.index):\n",
    "        return False\n",
    "    elif str(block1.previousHash) != str(block2.previousHash):\n",
    "        return False\n",
    "    elif str(block1.timestamp) != str(block2.timestamp):\n",
    "        return False\n",
    "    elif str(block1.data) != str(block2.data):\n",
    "        return False\n",
    "    elif str(block1.currentHash) != str(block2.currentHash):\n",
    "        return False\n",
    "    elif str(block1.proof) != str(block2.proof):\n",
    "        return False\n",
    "    elif str(block1.merkleHash) != str(block.merkleHash):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외부에서 받은 블록들을 비교한다(순서 6개의 경우: [1,2], [2,3] ... [5,6]\n",
    "def isValidNewBlock(newBlock, previousBlock):\n",
    "    if int(previousBlock.index) + 1 != int(newBlock.index):\n",
    "        print('Indices Do Not Match Up')\n",
    "        return False\n",
    "    # 체이닝이 맞는지\n",
    "    elif previousBlock.currentHash != newBlock.previousHash:\n",
    "        print(\"Previous hash does not match\")\n",
    "        return False\n",
    "    # 해쉬검증\n",
    "    elif calculateHashForBlock(newBlock) != newBlock.currentHash:\n",
    "        print(\"Hash is invalid\")\n",
    "        return False\n",
    "    elif newBlock.currentHash[0:g_difficulty] != '0' * g_difficulty:\n",
    "        print(\"Hash difficulty is invalid\")\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------V02 : 완\n",
    "#\n",
    "def newtx(txToMining, mode='new'):\n",
    "    newtxData = []\n",
    "    if mode == 'new' :\n",
    "        print(\"newTxData\")\n",
    "        # transform given data to txData object\n",
    "        for line in txToMining:\n",
    "            # -----------------------------------------V02 : 완\n",
    "            # txData생성시 거래시간 추가\n",
    "            tx = txData(0, line['sender'], line['amount'], line['receiver'], line['fee'], uuid.uuid4(), time.time())\n",
    "            newtxData.append(tx)\n",
    "\n",
    "        # limitation check : max 5 tx\n",
    "        if len(newtxData) > 5:\n",
    "            print('number of requested tx exceeds limitation')\n",
    "            return -1\n",
    "\n",
    "        if writeTx(newtxData) == 0:\n",
    "            print(\"file write error on txData\")\n",
    "            return -2\n",
    "\n",
    "        syncTxBetweenSvr(newtxData)\n",
    "    #mode가 'sync'인경우\n",
    "    else :\n",
    "        print(\"sync TxData\")\n",
    "        for line in txToMining:\n",
    "            # -----------------------------------------V02 : 완\n",
    "            # mode가 'sync'이면 바로 write\n",
    "            tx = txData(line['commitYN'], line['sender'], line['amount'], line['receiver'], line['fee'], line['uuid'], line['transactionTime'])\n",
    "            newtxData.append(tx)\n",
    "            writeTx(newtxData)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------V02 : 실패\n",
    " # g_nodeList의 목록을 읽어와 txData가 추가될 때마다 동기화 시킨다.\n",
    "def syncTxBetweenSvr(newTxData) :\n",
    "\n",
    "    reqHeader = {'Content-Type': 'application/json; charset=utf-8'}\n",
    "    reqBody = []\n",
    "    reqBody.append(newTxData)\n",
    "\n",
    "    for key, value in g_nodeList.items():\n",
    "        try:\n",
    "            URL = \"http://\" + key + \":\" + value + \"/block/syncTx\"\n",
    "            res = requests.post(URL, headers=reqHeader, data=json.dumps(reqBody))\n",
    "\n",
    "            if res.status_code == 200:\n",
    "                print(URL + \" sent ok.\")\n",
    "                print(newTxData)\n",
    "                print(\"Response Message \" + res.text)\n",
    "            else:\n",
    "                print(URL + \" responding error \" + res.status_code)\n",
    "        except:\n",
    "            print(\"Trusted Server \" + URL + \" is not responding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isValidChain(bcToValidate):\n",
    "    genesisBlock = []\n",
    "    bcToValidateForBlock = []\n",
    "\n",
    "    # Read GenesisBlock\n",
    "    try:\n",
    "        with open(g_bcFileName, 'r', newline='') as file:\n",
    "            blockReader = csv.reader(file)\n",
    "            for line in blockReader:\n",
    "                block = Block(line[0], line[1], line[2], line[3], line[4], line[5], line[6])\n",
    "                genesisBlock.append(block)\n",
    "    #                break\n",
    "    except:\n",
    "        print(\"file open error in isValidChain\")\n",
    "        return False\n",
    "\n",
    "    # transform given data to Block object\n",
    "    for line in bcToValidate:\n",
    "        # print(type(line))\n",
    "        # index, previousHash, timestamp, data, currentHash, proof\n",
    "        block = Block(line['index'], line['previousHash'], line['timestamp'], line['data'], line['currentHash'],\n",
    "                      line['proof'], line['merkleHash'])\n",
    "        bcToValidateForBlock.append(block)\n",
    "\n",
    "    # if it fails to read block data  from db(csv)\n",
    "    if not genesisBlock:\n",
    "        print(\"fail to read genesisBlock\")\n",
    "        return False\n",
    "\n",
    "    # compare the given data with genesisBlock\n",
    "    if not isSameBlock(bcToValidateForBlock[0], genesisBlock[0]):\n",
    "        print('Genesis Block Incorrect')\n",
    "        return False\n",
    "\n",
    "    # tempBlocks = [bcToValidateForBlock[0]]\n",
    "    # for i in range(1, len(bcToValidateForBlock)):\n",
    "    #    if isValidNewBlock(bcToValidateForBlock[i], tempBlocks[i - 1]):\n",
    "    #        tempBlocks.append(bcToValidateForBlock[i])\n",
    "    #    else:\n",
    "    #        return False\n",
    "\n",
    "    for i in range(0, len(bcToValidateForBlock)):\n",
    "        if isSameBlock(genesisBlock[i], bcToValidateForBlock[i]) == False:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드를 추가하는 메소드.인자는 요청받은 곳의 ip주소와 port번호\n",
    "def addNode(queryStr):\n",
    "    # save\n",
    "    txDataList = []\n",
    "    # ip주소와 port번호와 함께 추가적으로 연결시도횟수를 리스트에 입력한다. 처음은 당연히 0.\n",
    "    txDataList.append([queryStr[0], queryStr[1], 0])  # ip, port, # of connection fail\n",
    "    # 쓰기용으로 임시파일스트림을 연다.\n",
    "    tempfile = NamedTemporaryFile(mode='w', newline='', delete=False)\n",
    "    # 읽기용으로 \"nodelst.csv\" 파일스트림을 연다. 단, 해당 파일이 존재하지않으면 except로 빠진다.\n",
    "    try:\n",
    "        with open(g_nodelstFileName, 'r', newline='') as csvfile, tempfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            writer = csv.writer(tempfile)\n",
    "            for row in reader:\n",
    "                if row:\n",
    "                    if row[0] == queryStr[0] and row[1] == queryStr[1]:\n",
    "                        print(\"requested node is already exists\")\n",
    "                        csvfile.close()\n",
    "                        tempfile.close()\n",
    "                        return -1\n",
    "                    else:\n",
    "                        writer.writerow(row)\n",
    "            writer.writerows(txDataList)\n",
    "        shutil.move(tempfile.name, g_nodelstFileName)\n",
    "        csvfile.close()\n",
    "        tempfile.close()\n",
    "    # \"nodelst.csv\"파일이 존재하지 않는 경우\n",
    "    except:\n",
    "        # this is 1st time of creating node list\n",
    "        try:\n",
    "            # 쓰기용으로 \"nodelst.csv\"이름이 파일스트림을 연다. 존재하지 않으면 새로 생성\n",
    "            with open(g_nodelstFileName, \"w\", newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerows(txDataList)\n",
    "        # 파일스트림을 여는데 실패한 경우 return 0\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    return 1\n",
    "    print('new node written to nodelist.csv.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_nodelstFileName, \"nodelst.csv\"의 내용을 읽어온다.\n",
    "def readNodes(filePath):\n",
    "    print(\"read Nodes\")\n",
    "    importedNodes = []\n",
    "\n",
    "    try:\n",
    "\n",
    "        with open(filePath, 'r', newline='') as file:\n",
    "            txReader = csv.reader(file)\n",
    "\n",
    "            for row in txReader:\n",
    "                line = [row[0], row[1]]\n",
    "                importedNodes.append(line)\n",
    "        print(\"Pulling txData from csv...\")\n",
    "        return importedNodes\n",
    "    except:\n",
    "\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcastNewBlock(blockchain):\n",
    "\n",
    "    importedNodes = readNodes(g_nodelstFileName)  # get server node ip and port\n",
    "\n",
    "    reqHeader = {'Content-Type': 'application/json; charset=utf-8'}\n",
    "\n",
    "    reqBody = []\n",
    "\n",
    "    for i in blockchain:\n",
    "       reqBody.append(i.__dict__)\n",
    "\n",
    "    if len(importedNodes) > 0:\n",
    "        for node in importedNodes:\n",
    "            try:\n",
    "\n",
    "                URL = \"http://\" + node[0] + \":\" + node[\n",
    "                    1] + g_receiveNewBlock  # 형태 : http://ip:port/node/receiveNewBlock\n",
    "\n",
    "                res = requests.post(URL, headers=reqHeader, data=json.dumps(reqBody))\n",
    "\n",
    "                if res.status_code == 200:\n",
    "                    print(URL + \" sent ok.\")\n",
    "                    print(\"Response Message \" + res.text)\n",
    "\n",
    "                else:\n",
    "                    print(URL + \" responding error \" + res.status_code)\n",
    "\n",
    "            except:\n",
    "                print(URL + \" is not responding.\")\n",
    "                # write responding results\n",
    "\n",
    "                tempfile = NamedTemporaryFile(mode='w', newline='', delete=False)\n",
    "                try:\n",
    "\n",
    "                    # 해당 파일이 존재하지않다면, except로 빠진다.\n",
    "                    with open(g_nodelstFileName, 'r', newline='') as csvfile, tempfile:\n",
    "                        reader = csv.reader(csvfile)\n",
    "                        writer = csv.writer(tempfile)\n",
    "\n",
    "                        for row in reader:\n",
    "                            # if row?\n",
    "                            if row:\n",
    "\n",
    "                                if row[0] == node[0] and row[1] == node[1]:\n",
    "                                    print(\"connection failed \" + row[0] + \":\" + row[1] + \", number of fail \" + row[2])\n",
    "\n",
    "                                    tmp = row[2]\n",
    "                                    if int(tmp) > g_maximumTry:\n",
    "                                        print(row[0] + \":\" + row[\n",
    "                                            1] + \" deleted from node list because of exceeding the request limit\")\n",
    "\n",
    "                                    else:\n",
    "\n",
    "                                        row[2] = int(tmp) + 1\n",
    "                                        writer.writerow(row)\n",
    "\n",
    "                                else:\n",
    "                                    writer.writerow(row)\n",
    "\n",
    "                    shutil.move(tempfile.name, g_nodelstFileName)\n",
    "\n",
    "                    csvfile.close()\n",
    "                    tempfile.close()\n",
    "\n",
    "                except:\n",
    "                    print(\"caught exception while updating node list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_count(filename):\n",
    "    try:\n",
    "        with open(filename) as in_file:\n",
    "            return sum(1 for _ in in_file)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareMerge(bcDict):\n",
    "    heldBlock = []\n",
    "    bcToValidateForBlock = []\n",
    "\n",
    "    # Read GenesisBlock\n",
    "    try:\n",
    "        with open(g_bcFileName, 'r', newline='') as file:\n",
    "            blockReader = csv.reader(file)\n",
    "            # last_line_number = row_count(g_bcFileName)\n",
    "            for line in blockReader:\n",
    "                # -----------------------------------------V01 : 완\n",
    "                # line[6] merkleHash 추가\n",
    "                block = Block(line[0], line[1], line[2], line[3], line[4], line[5], line[6])\n",
    "                heldBlock.append(block)\n",
    "                # if blockReader.line_num == 1:\n",
    "                #    block = Block(line[0], line[1], line[2], line[3], line[4], line[5])\n",
    "                #    heldBlock.append(block)\n",
    "                # elif blockReader.line_num == last_line_number:\n",
    "                #    block = Block(line[0], line[1], line[2], line[3], line[4], line[5])\n",
    "                #    heldBlock.append(block)\n",
    "\n",
    "    except:\n",
    "        print(\"file open error in compareMerge or No database exists\")\n",
    "        print(\"call initSvr if this server has just installed\")\n",
    "        return -1\n",
    "\n",
    "    # if it fails to read block data  from db(csv)\n",
    "    if len(heldBlock) == 0:\n",
    "        print(\"fail to read\")\n",
    "        return -2\n",
    "\n",
    "    # transform given data to Block object\n",
    "    for line in bcDict:\n",
    "        # print(type(line))\n",
    "        # index, previousHash, timestamp, data, currentHash, proof\n",
    "        # Block생성자로 객체를 생성하여 block에 넣는다.\n",
    "        # -----------------------------------------V01 : 완\n",
    "        # line['merkleHash'] merkleHash 추가\n",
    "        block = Block(line['index'], line['previousHash'], line['timestamp'], line['data'], line['currentHash'],\n",
    "                      line['proof'], line['merkleHash'])\n",
    "        # block객체형 list 변수에 다시 block객체를 넣는다\n",
    "        bcToValidateForBlock.append(block)\n",
    "\n",
    "    # compare the given data with genesisBlock\n",
    "    if not isSameBlock(bcToValidateForBlock[0], heldBlock[0]):\n",
    "        print('Genesis Block Incorrect')\n",
    "        return -1\n",
    "\n",
    "    # check if broadcasted new block,1 ahead than > last held block\n",
    "\n",
    "    if isValidNewBlock(bcToValidateForBlock[-1], heldBlock[-1]) == False:\n",
    "\n",
    "        # latest block == broadcasted last block\n",
    "        if isSameBlock(heldBlock[-1], bcToValidateForBlock[-1]) == True:\n",
    "            print('latest block == broadcasted last block, already updated')\n",
    "            return 2\n",
    "        # select longest chain\n",
    "        elif len(bcToValidateForBlock) > len(heldBlock):\n",
    "            # validation\n",
    "            if isSameBlock(heldBlock[0], bcToValidateForBlock[0]) == False:\n",
    "                print(\"Block Information Incorrect #1\")\n",
    "                return -1\n",
    "            tempBlocks = [bcToValidateForBlock[0]]\n",
    "            for i in range(1, len(bcToValidateForBlock)):\n",
    "                if isValidNewBlock(bcToValidateForBlock[i], tempBlocks[i - 1]):\n",
    "                    tempBlocks.append(bcToValidateForBlock[i])\n",
    "                else:\n",
    "                    return -1\n",
    "            # [START] save it to csv\n",
    "            blockchainList = []\n",
    "            for block in bcToValidateForBlock:\n",
    "                blockList = [block.index, block.previousHash, str(block.timestamp), block.data,\n",
    "                             block.currentHash, block.proof]\n",
    "                blockchainList.append(blockList)\n",
    "            with open(g_bcFileName, \"w\", newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerows(blockchainList)\n",
    "            # [END] save it to csv\n",
    "            return 1\n",
    "        elif len(bcToValidateForBlock) < len(heldBlock):\n",
    "            # validation\n",
    "            # for i in range(0,len(bcToValidateForBlock)):\n",
    "            #    if isSameBlock(heldBlock[i], bcToValidateForBlock[i]) == False:\n",
    "            #        print(\"Block Information Incorrect #1\")\n",
    "            #        return -1\n",
    "            tempBlocks = [bcToValidateForBlock[0]]\n",
    "            for i in range(1, len(bcToValidateForBlock)):\n",
    "                if isValidNewBlock(bcToValidateForBlock[i], tempBlocks[i - 1]):\n",
    "                    tempBlocks.append(bcToValidateForBlock[i])\n",
    "                else:\n",
    "                    return -1\n",
    "            print(\"We have a longer chain\")\n",
    "            return 3\n",
    "        else:\n",
    "            print(\"Block Information Incorrect #2\")\n",
    "            return -1\n",
    "    else:  # very normal case (ex> we have index 100 and receive index 101 ...)\n",
    "        tempBlocks = [bcToValidateForBlock[0]]\n",
    "        for i in range(1, len(bcToValidateForBlock)):\n",
    "            if isValidNewBlock(bcToValidateForBlock[i], tempBlocks[i - 1]):\n",
    "                tempBlocks.append(bcToValidateForBlock[i])\n",
    "            else:\n",
    "                print(\"Block Information Incorrect #2 \" + tempBlocks.__dict__)\n",
    "                return -1\n",
    "\n",
    "        print(\"new block good\")\n",
    "\n",
    "        # validation\n",
    "        for i in range(0, len(heldBlock)):\n",
    "            if isSameBlock(heldBlock[i], bcToValidateForBlock[i]) == False:\n",
    "                print(\"Block Information Incorrect #1\")\n",
    "                return -1\n",
    "        # [START] save it to csv\n",
    "        blockchainList = []\n",
    "        for block in bcToValidateForBlock:\n",
    "            blockList = [block.index, block.previousHash, str(block.timestamp), block.data, block.currentHash,\n",
    "                         block.proof]\n",
    "            blockchainList.append(blockList)\n",
    "        with open(g_bcFileName, \"w\", newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(blockchainList)\n",
    "        # [END] save it to csv\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initSvr():\n",
    "    print(\"init Server\")\n",
    "    # 1. check if we have a node list file\n",
    "    last_line_number = row_count(g_nodelstFileName)\n",
    "    # if we don't have, let's request node list\n",
    "    if last_line_number == 0:\n",
    "        # get nodes...\n",
    "        for key, value in g_nodeList.items():\n",
    "            URL = 'http://' + key + ':' + value + '/node/getNode'\n",
    "            try:\n",
    "                res = requests.get(URL)\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                continue\n",
    "            if res.status_code == 200:\n",
    "                print(res.text)\n",
    "                tmpNodeLists = json.loads(res.text)\n",
    "                for node in tmpNodeLists:\n",
    "                    addNode(node)\n",
    "\n",
    "    # 2. check if we have a blockchain data file\n",
    "    last_line_number = row_count(g_bcFileName)\n",
    "    blockchainList = []\n",
    "    if last_line_number == 0:\n",
    "        try:\n",
    "            with conn.cursor() as cursor: \n",
    "                sql = '''\n",
    "                    CREATE TABLE block (\n",
    "                        index int(100) NOT NULL AUTO_INCREMENT PRIMARY KEY,                    \n",
    "                        previousHash varchar(255) NOT NULL,\n",
    "                        timestamp int(100) NOT NULL,\n",
    "                        data varchar(255) NOT NULL,\n",
    "                        currentHash varchar(255) NOT NULL,\n",
    "                        proof int(100) NOT NULL,\n",
    "                        merkleHash varchar(255) NOT NULL\n",
    "                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8\n",
    "                        '''\n",
    "                cursor.execute(sql)\n",
    "            conn.commit()                \n",
    "        finally:\n",
    "            conn.close()\n",
    "        # get Block Data...\n",
    "        for key, value in g_nodeList.items():\n",
    "            URL = 'http://' + key + ':' + value + '/block/getBlockData'\n",
    "            try:\n",
    "                res = requests.get(URL)\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                continue\n",
    "            if res.status_code == 200:\n",
    "                print(res.text)\n",
    "                tmpbcData = json.loads(res.text)\n",
    "                for line in tmpbcData:\n",
    "                    # print(type(line))\n",
    "                    # index, previousHash, timestamp, data, currentHash, proof, merkleHash\n",
    "                    # -----------------------------------------V01 : 완\n",
    "                    # line['merkleHash'] merkleHash 추가\n",
    "                    block = [line['index'], line['previousHash'], line['timestamp'], line['data'], line['currentHash'],\n",
    "                             line['proof'], line['merkleHash']]\n",
    "                    blockchainList.append(block)\n",
    "                try:\n",
    "                    with open(g_bcFileName, \"w\", newline='') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerows(blockchainList)\n",
    "                except Exception as e:\n",
    "                    print(\"file write error in initSvr() \" + e)\n",
    "    # -----------------------------------------V02 : 완\n",
    "    # 3. check if we have a txData file\n",
    "#     last_line_number = row_count(g_txFileName)\n",
    "#     txDataList = []\n",
    "#     if last_line_number == 0:\n",
    "#         # get txData...\n",
    "#         for key, value in g_nodeList.items():\n",
    "#             URL = 'http://' + key + ':' + value + '/txData/getTxData'\n",
    "#             try:\n",
    "#                 res = requests.get(URL)\n",
    "#             except requests.exceptions.ConnectionError:\n",
    "#                 continue\n",
    "#             if res.status_code == 200:\n",
    "#                 print(res.text)\n",
    "#                 tmpTxData = json.loads(res.text)\n",
    "#                 for line in tmpTxData:\n",
    "#                     # print(type(line))\n",
    "#                     # amount, commitYN, fee, receiver, sender, uuid\n",
    "#                     txData = [line['commitYN'],line['receiver'], line['amount'], line['sender'], line['fee'],\n",
    "#                              line['uuid'], line['transactionTime']]\n",
    "#                     txDataList.append(txData)\n",
    "#                 try:\n",
    "#                     with open(g_txFileName, \"w\", newline='') as file:\n",
    "#                         writer = csv.writer(file)\n",
    "#                         writer.writerows(txDataList)\n",
    "#                 except Exception as e:\n",
    "#                     print(\"file write error in initSvr() \" + e)\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will handle any incoming request from\n",
    "# a browser\n",
    "class myHandler(BaseHTTPRequestHandler):\n",
    "\n",
    "    # def __init__(self, request, client_address, server):\n",
    "    #    BaseHTTPRequestHandler.__init__(self, request, client_address, server)\n",
    "\n",
    "    # Handler for the GET requests\n",
    "    # get방식으로 보내는 요청의 종류로는 블록체인의 데이터 요청, 블록 생성, 노드데이터 요청, 노드생성이 존재한다.\n",
    "    def do_GET(self):\n",
    "        data = []  # response json data\n",
    "        if None != re.search('/block/*', self.path):\n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-type', 'application/json')\n",
    "            self.end_headers()\n",
    "\n",
    "            if None != re.search('/block/getBlockData', self.path):\n",
    "\n",
    "                block = readBlockchain(g_bcFileName, mode='external')\n",
    "\n",
    "                # block의 값이 None인 경우\n",
    "                if block == None:\n",
    "\n",
    "                    print(\"No Block Exists\")\n",
    "\n",
    "                    data.append(\"no data exists\")\n",
    "                else:\n",
    "                    for i in block:\n",
    "                        print(i.__dict__)\n",
    "                        data.append(i.__dict__)\n",
    "\n",
    "                self.wfile.write(bytes(json.dumps(data, sort_keys=True, indent=4), \"utf-8\"))\n",
    "\n",
    "            # 블럭을 생성하는 경우 (최초, 그 이후 전부)\n",
    "            elif None != re.search('/block/generateBlock', self.path):\n",
    "\n",
    "                t = threading.Thread(target=mine)\n",
    "                t.start()\n",
    "                data.append(\"{mining is underway:check later by calling /block/getBlockData}\")\n",
    "                self.wfile.write(bytes(json.dumps(data, sort_keys=True, indent=4), \"utf-8\"))\n",
    "            else:\n",
    "                data.append(\"{info:no such api}\")\n",
    "                self.wfile.write(bytes(json.dumps(data, sort_keys=True, indent=4), \"utf-8\"))\n",
    "\n",
    "\n",
    "        elif None != re.search('/node/*', self.path):\n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-type', 'application/json')\n",
    "            self.end_headers()\n",
    "\n",
    "            if None != re.search('/node/addNode', self.path):\n",
    "\n",
    "                queryStr = urlparse(self.path).query.split(':')\n",
    "                print(\"client ip : \" + self.client_address[0] + \" query ip : \" + queryStr[0])\n",
    "\n",
    "                if self.client_address[0] != queryStr[0]:\n",
    "                    data.append(\"your ip address doesn't match with the requested parameter\")\n",
    "\n",
    "                else:\n",
    "                    res = addNode(queryStr)\n",
    "\n",
    "                    if res == 1:\n",
    "                        importedNodes = readNodes(g_nodelstFileName)\n",
    "                        data = importedNodes\n",
    "                        print(\"node added okay\")\n",
    "\n",
    "                    elif res == 0:\n",
    "                        data.append(\"caught exception while saving\")\n",
    "\n",
    "                    elif res == -1:\n",
    "                        importedNodes = readNodes(g_nodelstFileName)\n",
    "                        data = importedNodes\n",
    "                        data.append(\"requested node is already exists\")\n",
    "\n",
    "                self.wfile.write(bytes(json.dumps(data, sort_keys=True, indent=4), \"utf-8\"))\n",
    "\n",
    "            elif None != re.search('/node/getNode', self.path):\n",
    "                importedNodes = readNodes(g_nodelstFileName)\n",
    "                data = importedNodes\n",
    "                self.wfile.write(bytes(json.dumps(data, sort_keys=True, indent=4), \"utf-8\"))\n",
    "\n",
    "        # -----------------------------------------V02 : 완\n",
    "        # txData 요청에 대한 response 부분 추가. mode=''인 경우는 모든 데이터를 가져온다.\n",
    "        elif None != re.search('/txData/*', self.path):\n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-type', 'application/json')\n",
    "            self.end_headers()\n",
    "\n",
    "            if None != re.search('/txData/getTxData', self.path):\n",
    "\n",
    "                txDataList = readTx(g_txFileName, mode='external')\n",
    "\n",
    "                if txDataList == '':\n",
    "\n",
    "                    print(\"No txData Exists\")\n",
    "\n",
    "                    data.append(\"no txData exists\")\n",
    "                else:\n",
    "                    for i in txDataList:\n",
    "                        print(i.__dict__)\n",
    "                        data.append(i.__dict__)\n",
    "\n",
    "                self.wfile.write(bytes(json.dumps(data, sort_keys=True, indent=4), \"utf-8\"))\n",
    "        else:\n",
    "            self.send_response(403)\n",
    "            self.send_header('Content-Type', 'application/json')\n",
    "            self.end_headers()\n",
    "        # ref : https://mafayyaz.wordpress.com/2013/02/08/writing-simple-http-server-in-python-with-rest-and-json/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def do_POST(self):\n",
    "\n",
    "        if None != re.search('/block/*', self.path):\n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-type', 'application/json')\n",
    "            self.end_headers()\n",
    "\n",
    "            if None != re.search('/block/validateBlock/*', self.path):\n",
    "                ctype, pdict = cgi.parse_header(self.headers['content-type'])\n",
    "                # print(ctype) #print(pdict)\n",
    "\n",
    "                if ctype == 'application/json':\n",
    "                    content_length = int(self.headers['Content-Length'])\n",
    "                    post_data = self.rfile.read(content_length)\n",
    "                    receivedData = post_data.decode('utf-8')\n",
    "                    print(type(receivedData))\n",
    "                    tempDict = json.loads(receivedData)  # load your str into a list #print(type(tempDict))\n",
    "                    if isValidChain(tempDict) == True:\n",
    "                        tempDict.append(\"validationResult:normal\")\n",
    "                        self.wfile.write(bytes(json.dumps(tempDict), \"utf-8\"))\n",
    "                    else:\n",
    "                        tempDict.append(\"validationResult:abnormal\")\n",
    "                        self.wfile.write(bytes(json.dumps(tempDict), \"utf-8\"))\n",
    "\n",
    "            elif None != re.search('/block/newtx', self.path):\n",
    "                ctype, pdict = cgi.parse_header(self.headers['content-type'])\n",
    "                if ctype == 'application/json':\n",
    "                    content_length = int(self.headers['Content-Length'])\n",
    "                    post_data = self.rfile.read(content_length)\n",
    "                    receivedData = post_data.decode('utf-8')\n",
    "                    print(type(receivedData))\n",
    "                    tempDict = json.loads(receivedData)\n",
    "                    res = newtx(tempDict)\n",
    "                    if res == 1:\n",
    "                        tempDict.append(\"accepted : it will be mined later\")\n",
    "                        self.wfile.write(bytes(json.dumps(tempDict), \"utf-8\"))\n",
    "                    elif res == -1:\n",
    "                        tempDict.append(\"declined : number of request txData exceeds limitation\")\n",
    "                        self.wfile.write(bytes(json.dumps(tempDict), \"utf-8\"))\n",
    "                    elif res == -2:\n",
    "                        tempDict.append(\"declined : error on data read or write\")\n",
    "                        self.wfile.write(bytes(json.dumps(tempDict), \"utf-8\"))\n",
    "                    else:\n",
    "                        tempDict.append(\"error : requested data is abnormal\")\n",
    "                        self.wfile.write(bytes(json.dumps(tempDict), \"utf-8\"))\n",
    "\n",
    "            # -----------------------------------------V02 : 완\n",
    "            # \"/block/syncTx'\" 로 오는 요청은 다시 sync과정을 거치지 않는다.\n",
    "            elif None != re.search('/block/syncTx', self.path) :\n",
    "                ctype, pdict = cgi.parse_header(self.headers['content-type'])\n",
    "                if ctype == 'application/json':\n",
    "                    content_length = int(self.headers['Content-Length'])\n",
    "                    post_data = self.rfile.read(content_length)\n",
    "                    receivedData = post_data.decode('utf-8')\n",
    "                    print(type(receivedData))\n",
    "                    tempDict = json.loads(receivedData)\n",
    "                    res = newtx(tempDict, mode='sync')\n",
    "\n",
    "                    if res == 1:\n",
    "                        tempDict.append(\"accepted : it will be mined later\")\n",
    "                        self.wfile.write(bytes(json.dumps(tempDict), \"utf-8\"))\n",
    "                    elif res == -1:\n",
    "                        tempDict.append(\"declined : number of request txData exceeds limitation\")\n",
    "                        self.wfile.write(bytes(json.dumps(tempDict), \"utf-8\"))\n",
    "                    elif res == -2:\n",
    "                        tempDict.append(\"declined : error on data read or write\")\n",
    "                        self.wfile.write(bytes(json.dumps(tempDict), \"utf-8\"))\n",
    "                    else:\n",
    "                        tempDict.append(\"error : requested data is abnormal\")\n",
    "                        self.wfile.write(bytes(json.dumps(tempDict), \"utf-8\"))\n",
    "\n",
    "        elif None != re.search('/node/*', self.path):\n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-type', 'application/json')\n",
    "            self.end_headers()\n",
    "\n",
    "            if None != re.search(g_receiveNewBlock, self.path):  # /node/receiveNewBlock\n",
    "                content_length = int(self.headers['Content-Length'])\n",
    "                post_data = self.rfile.read(content_length)\n",
    "                receivedData = post_data.decode('utf-8')\n",
    "                tempDict = json.loads(receivedData)  # load your str into a list\n",
    "                print(tempDict)\n",
    "                res = compareMerge(tempDict)\n",
    "                if res == -1:  # internal error\n",
    "                    tempDict.append(\"internal server error\")\n",
    "                elif res == -2:  # block chain info incorrect\n",
    "                    tempDict.append(\"block chain info incorrect\")\n",
    "                elif res == 1:  # normal\n",
    "                    tempDict.append(\"accepted\")\n",
    "                elif res == 2:  # identical\n",
    "                    tempDict.append(\"already updated\")\n",
    "                elif res == 3:  # we have a longer chain\n",
    "                    tempDict.append(\"we have a longer chain\")\n",
    "                self.wfile.write(bytes(json.dumps(tempDict), \"utf-8\"))\n",
    "\n",
    "        else:\n",
    "            self.send_response(404)\n",
    "            self.send_header('Content-Type', 'application/json')\n",
    "            self.end_headers()\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started httpserver on port  8099\n",
      "init Server\n",
      "^C received, shutting down the web server\n",
      "Already closed\n"
     ]
    }
   ],
   "source": [
    "class ThreadedHTTPServer(ThreadingMixIn, HTTPServer):\n",
    "    \"\"\"Handle requests in a separate thread.\"\"\"\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    # Create a web server and define the handler to manage the\n",
    "    # incoming request\n",
    "    # server = HTTPServer(('', PORT_NUMBER), myHandler)\n",
    "    server = ThreadedHTTPServer(('', PORT_NUMBER), myHandler)\n",
    "    print('Started httpserver on port ', PORT_NUMBER)\n",
    "\n",
    "    initSvr()\n",
    "    # Wait forever for incoming http requests\n",
    "    server.serve_forever()\n",
    "\n",
    "except (KeyboardInterrupt, Exception) as e:\n",
    "    print('^C received, shutting down the web server')\n",
    "    print(e)\n",
    "    server.socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
